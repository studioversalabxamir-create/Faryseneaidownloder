import os
import requests
import asyncio
import aiohttp
# from config import PROXY  # No longer needed - using rotating proxies
from concurrent.futures import ThreadPoolExecutor
from bs4 import BeautifulSoup
from aiogram import Router, types
from fake_useragent import UserAgent
import logging
from urllib.parse import urlparse
import json
import re
import time  # Ø¨Ø±Ø§ÛŒ Ø²Ù…Ø§Ù†â€ŒØ³Ù†Ø¬ÛŒ

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯ÛŒÙ†Ú¯
logging.basicConfig(level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# Ø±ÙˆØªØ± Ùˆ ØªØ±Ø¯Ù¾ÙˆÙ„
router = Router()
executor = ThreadPoolExecutor(max_workers=5)  # Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ù‡ 5 Ø¨Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ØªØ±

# Proxy configuration - import from centralized config
try:
    from config import PROXY
    WORKING_PROXIES = [PROXY] if PROXY else []
except ImportError:
    WORKING_PROXIES = []

# Ø´Ø§Ø®Øµ Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ú†Ø±Ø®Ø´
proxy_index = 0

def get_next_proxy():
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ú†Ø±Ø®Ø´"""
    global proxy_index
    if not WORKING_PROXIES:
        return None
    proxy = WORKING_PROXIES[proxy_index]
    proxy_index = (proxy_index + 1) % len(WORKING_PROXIES)
    return proxy

ua = UserAgent()

def normalize_pin_url(url):
    """Normalize Pinterest CDN URLs to get original quality images"""
    return url.replace("/236x/", "/originals/") \
              .replace("/474x/", "/originals/") \
              .replace("/736x/", "/originals/")

async def pinterest_download(url, ext):
    """
    Pinterest-safe download function with fallback support
    Returns local file path
    """
    # Ensure temp directory exists
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    
    # Generate unique filename
    filename = f"pin_{int(time.time())}{ext}"
    local_path = os.path.join(temp_dir, filename)
    
    # Normalize URL for better quality
    url = normalize_pin_url(url)
    
    # Real browser headers
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
        "Referer": "https://www.pinterest.com/",
        "Accept": "*/*",
        "Accept-Language": "en-US,en;q=0.9",
        "Connection": "keep-alive"
    }
    
    # First attempt: no cookie
    async with aiohttp.ClientSession() as session:
        async with session.get(url, headers=headers) as response:
            if response.status == 200:
                with open(local_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(8192):
                        f.write(chunk)
                return local_path
            
            # Fallback: retry with cookies if 403
            if response.status == 403:
                headers_with_cookie = headers.copy()
                headers_with_cookie["Cookie"] = "session=valid; csrftoken=valid"
                
                async with session.get(url, headers=headers_with_cookie) as retry_response:
                    if retry_response.status == 200:
                        with open(local_path, 'wb') as f:
                            async for chunk in retry_response.content.iter_chunked(8192):
                                f.write(chunk)
                        return local_path
    
    raise Exception("Pinterest download failed")

# ØªØ§Ø¨Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆØ¶ÛŒØ­Ø§Øª
def extract_description(html: str):
    if 'og:description" content="' in html:
        start = html.find('og:description" content="') + len('og:description" content="')
        end = html.find('"', start)
        return html[start:end]
    return None

from task_manager import task_manager

import asyncio
import re

# Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ø§ÛŒÙ†Ù‡Ø§ Ø±Ùˆ Ø§Ø² Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯ÛŒ:
# from utils import fetch_pinterest_content, fetch_pinterest_profile, handle_multiple_pinterest_links
# from config import executor, errors_total, logger

@router.message(lambda m: m.text and ("pinterest.com" in m.text.lower() or "pin.it" in m.text.lower()))
async def pinterest_download_handler(message: types.Message):
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Pinterest Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² cancel (ÙÙ„Ú¯ Ø¯Ø± task_manager)
    """

    async def process_pinterest_download():
        user_id = message.from_user.id

        text = message.text.strip()
        urls = re.findall(r'https?://[^\s]+', text)
        pinterest_urls = [u for u in urls if 'pinterest.com' in u or 'pin.it' in u]

        # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÛŒØ¹ ÙÙ„Ú¯ Ù„ØºÙˆ Ù‚Ø¨Ù„ Ø§Ø² Ø´Ø±ÙˆØ¹
        if getattr(task_manager, "cancel_flags", {}).get(user_id):
            await message.answer("ğŸš« Operation canceled by user.")
            return

        # Ø§Ú¯Ø± Ú†Ù†Ø¯ Ù„ÛŒÙ†Ú© Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ (Ù¾Ø±ÙˆÙØ§ÛŒÙ„ ÛŒØ§ Ú†Ù†Ø¯ Ù¾ÛŒÙ†)
        if 2 <= len(pinterest_urls) <= 5:
            await handle_multiple_pinterest_links(message, pinterest_urls)
            return
        elif len(pinterest_urls) != 1:
            await message.answer("âš ï¸ Please send exactly 1 or 2â€“5 Pinterest links.")
            return

        url = pinterest_urls[0]
        loading_message = await message.answer("We are processing your request...")

        try:
            loop = asyncio.get_running_loop()

            # Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙÙ„Ú¯ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø³Ù†Ú¯ÛŒÙ†
            if getattr(task_manager, "cancel_flags", {}).get(user_id):
                await message.bot.edit_message_text(
                    chat_id=message.chat.id,
                    message_id=loading_message.message_id,
                    text="ğŸš« Operation canceled before processing started."
                )
                return

            # Ø­Ø§Ù„Øª: Pin Ù…Ø³ØªÙ‚ÛŒÙ… (Ø¹Ú©Ø³ / ÙˆÛŒØ¯ÛŒÙˆ)
            if "/pin/" in url or "pin.it" in url:
                content_type, file_url, caption = await loop.run_in_executor(
                    executor, fetch_pinterest_content, url
                )

                # Ú†Ú© Ù„ØºÙˆ Ø­ÛŒÙ† ÛŒØ§ Ø¨Ø¹Ø¯ Ø§Ø² Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² executor
                if getattr(task_manager, "cancel_flags", {}).get(user_id):
                    await message.bot.edit_message_text(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        text="ğŸš« Operation canceled during processing."
                    )
                    return

                if not file_url:
                    await message.bot.edit_message_text(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        text="âŒ Failed to retrieve file URL. Please try again later."
                    )
                    return

                if content_type == "image":
                    local_file = await pinterest_download(file_url, ".jpg")
                    sent_msg = await message.bot.edit_message_media(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        media=types.InputMediaPhoto(
                            media=types.FSInputFile(local_file), caption=caption, parse_mode="Markdown"
                        )
                    )
                    # Record download history
                    if sent_msg:
                        try:
                            from bot import record_download
                            file_size = os.path.getsize(local_file) if os.path.exists(local_file) else None
                            await record_download(
                                user_id, "pinterest", url,
                                file_type="image",
                                file_size=file_size
                            )
                        except Exception as hist_e:
                            logger.debug(f"Failed to record download history: {hist_e}")
                elif content_type == "video":
                    local_file = await pinterest_download(file_url, ".mp4")
                    sent_msg = await message.bot.edit_message_media(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        media=types.InputMediaVideo(
                            media=types.FSInputFile(local_file), caption=caption, parse_mode="Markdown"
                        )
                    )
                    # Record download history
                    if sent_msg:
                        try:
                            from bot import record_download
                            file_size = os.path.getsize(local_file) if os.path.exists(local_file) else None
                            await record_download(
                                user_id, "pinterest", url,
                                file_type="video",
                                file_size=file_size
                            )
                        except Exception as hist_e:
                            logger.debug(f"Failed to record download history: {hist_e}")
                else:
                    await message.bot.edit_message_text(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        text="âŒ Sorry, couldn't detect the content type."
                    )

            # Ø­Ø§Ù„Øª: Ù¾Ø±ÙˆÙØ§ÛŒÙ„
            else:
                profile_info = await loop.run_in_executor(
                    executor, fetch_pinterest_profile, url
                )

                # Ø¨Ø±Ø±Ø³ÛŒ ÙÙ„Ú¯ Ø¨Ø¹Ø¯ Ø§Ø² Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÙØ§ÛŒÙ„
                if getattr(task_manager, "cancel_flags", {}).get(user_id):
                    await message.bot.edit_message_text(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        text="ğŸš« Operation canceled by user."
                    )
                    return

                caption = (
                    f"Profile: [{profile_info['username']}]({profile_info['profile_url']})\n"
                    f"Pins: {profile_info['pins_count']}\n"
                    f"Description: {profile_info['description']}\n\n"
                    "Download by <a href='https://t.me/Faryseneaidownloder_bot'>Faryseneaidownloderbot</a>"
                )

                if profile_info.get('profile_image'):
                    local_file = await pinterest_download(profile_info['profile_image'], ".jpg")
                    await message.bot.edit_message_media(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        media=types.InputMediaPhoto(
                            media=types.FSInputFile(local_file), caption=caption, parse_mode="Markdown"
                        )
                    )
                else:
                    await message.bot.edit_message_text(
                        chat_id=message.chat.id,
                        message_id=loading_message.message_id,
                        text=caption,
                        parse_mode="Markdown"
                    )

            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
            try:
                await message.delete()
            except Exception:
                pass

        except asyncio.CancelledError:
            # Cancel was requested; update UI if possible, then re-raise to let TaskManager handle cleanup
            try:
                await message.bot.edit_message_text(
                    chat_id=message.chat.id,
                    message_id=loading_message.message_id,
                    text="ğŸš« Operation canceled by user."
                )
            except Exception:
                pass
            raise
        except Exception as e:
            logger.error(f"[Pinterest] Error: {e}", exc_info=True)
            await message.bot.edit_message_text(
                chat_id=message.chat.id,
                message_id=loading_message.message_id,
                text="âš ï¸ An unexpected error occurred. Please try again later."
            )

    # Ø§Ø¬Ø±Ø§ÛŒ Ú©Ù„ Ù…Ù†Ø·Ù‚ Ø¯Ø§Ø®Ù„ TaskManager (Ø¨Ø¯ÙˆÙ† Ù¾Ø±Ø§Ù†ØªØ² Ø¨Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹)
    await task_manager.start_task(message.from_user.id, process_pinterest_download)



# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ Ù¾ÛŒÙ†ØªØ±Ø³Øª (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡)
def fetch_pinterest_content(pin_url: str):
    start_time = time.time()
    session = requests.Session()  # Ø­ÙØ¸ Ø§ØªØµØ§Ù„ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
    headers = {"User-Agent": ua.random}

    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ú†Ø±Ø®Ø´ÛŒ
    for attempt in range(len(WORKING_PROXIES)):
        proxy = get_next_proxy()
        try:
            r = session.get(pin_url, headers=headers, proxies={"http": proxy, "https": proxy}, timeout=10)
            r.raise_for_status()
            break
        except Exception as e:
            logger.warning(f"Proxy failed (attempt {attempt + 1}): {proxy} - {e}")
            continue
    else:
        raise Exception("All proxies failed")

    soup = BeautifulSoup(r.text, "lxml")

    # ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨Ø§ selector Ø³Ø±ÛŒØ¹â€ŒØªØ±
    desc_tag = soup.select_one('meta[name="description"]')
    description = desc_tag.get("content") if desc_tag else None

    # ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÚ©ØŒ Ú©Ø§Ù…Ù†ØªØŒ ID Ù¾ÛŒÙ†â€ŒÚ©Ù†Ù†Ø¯Ù‡
    likes_count = ""
    comments_count = "Ù†Ø§Ù…Ø´Ø®Øµ"
    username = "Ù†Ø§Ù…Ø´Ø®Øµ"
    full_name = "Ù†Ø§Ù…Ø´Ø®Øµ"

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ JSON (Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ)
    def find_in_json(data, key, default="Ù†Ø§Ù…Ø´Ø®Øµ"):
        if isinstance(data, dict):
            if key in data:
                return str(data[key])
            for value in data.values():
                result = find_in_json(value, key, default)
                if result != default:
                    return result
        elif isinstance(data, list):
            for item in data:
                result = find_in_json(item, key, default)
                if result != default:
                    return result
        return default

    # ÙÙ‚Ø· Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§ÛŒ JSON Ø±Ùˆ select Ú©Ù†ÛŒØ¯ (Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø§Ø² find_all)
    scripts = soup.select('script[type="application/ld+json"], script[type="application/json"]')
    for script in scripts:
        if script.string:
            try:
                data = json.loads(script.string)
                likes_count = find_in_json(data, "save_count", likes_count) if likes_count == "Ù†Ø§Ù…Ø´Ø®Øµ" else likes_count
                likes_count = find_in_json(data, "aggregated_save_count", likes_count) if likes_count == "Ù†Ø§Ù…Ø´Ø®Øµ" else likes_count
                comments_count = find_in_json(data, "commentCount", comments_count)
                username = find_in_json(data, "username", username)
                full_name = find_in_json(data, "full_name", full_name)
            except json.JSONDecodeError:
                continue
            except Exception as e:
                logger.error(f"Error parsing script JSON: {e}")

    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡ (Ø¨Ø§ session)
    if likes_count == "Ù†Ø§Ù…Ø´Ø®Øµ" or comments_count == "Ù†Ø§Ù…Ø´Ø®Øµ" or username == "Ù†Ø§Ù…Ø´Ø®Øµ" or full_name == "Ù†Ø§Ù…Ø´Ø®Øµ":
        try:
            pin_id = pin_url.split("/")[-2] if "/pin/" in pin_url else None
            if pin_id:
                api_url = f"https://www.pinterest.com/resource/PinResource/get/?data={{\"options\":{{\"id\":\"{pin_id}\",\"field_set_key\":\"detailed\"}}}}"
                # Get fresh proxy for API request
                api_proxy = get_next_proxy()
                api_response = session.get(api_url, headers=headers, proxies={"http": api_proxy, "https": api_proxy}, timeout=10)
                api_response.raise_for_status()
                api_data = api_response.json()
                resource_data = api_data.get("resource_response", {}).get("data", {})
                
                aggregated_data = resource_data.get("aggregated_pin_data", {})
                likes_count = str(aggregated_data.get("aggregated_save_count", aggregated_data.get("save_count", likes_count)))
                comments_count = str(resource_data.get("comment_count", comments_count))
                pinner = resource_data.get("pinner", {})
                username = pinner.get("username", username)
                full_name = pinner.get("full_name", full_name)
        except Exception as e:
            logger.error(f"Error fetching PinResource: {e}")

    caption = f"Pin: [pin]({pin_url})\nLikes: {likes_count}\nComments: {comments_count}\nDescription: {description or 'No description'}\nSource: Pinterest\n\nDownload by Faryseneaidownloder_bot (https://t.me/Faryseneaidownloder_bot)"

    # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¹ Ù…Ø­ØªÙˆØ§ Ø¨Ø§ selector Ø³Ø±ÛŒØ¹â€ŒØªØ±
    video_tag = soup.select_one('meta[property="og:video"]')
    if video_tag and video_tag.get("content"):
        logger.info(f"Fetch time: {time.time() - start_time:.2f} seconds")
        return "video", video_tag["content"], caption

    # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø§Ø®Ù„ JSON Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ
    for script_tag in soup.select('script[type="application/ld+json"]'):
        try:
            data = json.loads(script_tag.string)
            if isinstance(data, dict) and "contentUrl" in data:
                logger.info(f"Fetch time: {time.time() - start_time:.2f} seconds")
                return "video", data["contentUrl"], caption
        except json.JSONDecodeError:
            logger.error("Error decoding ld+json script")
            continue
        except Exception as e:
            logger.error(f"Error processing ld+json: {e}")
            continue

    img_tag = soup.select_one('meta[property="og:image"]')
    if img_tag and img_tag.get("content"):
        img_url = img_tag["content"]
        if "i.pinimg.com" in img_url:
            img_url = img_url.replace("/236x/", "/originals/").replace("/474x/", "/originals/").replace("/736x/", "/originals/")
        logger.info(f"Fetch time: {time.time() - start_time:.2f} seconds")
        return "image", img_url, caption

    raise ValueError("Sorry, I couldn't detect the content of this pin. Please try again or contact support [@FaryseneAI_Support](https://t.me/FaryseneAI_Support).")

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡)
def fetch_pinterest_profile(profile_url: str):
    start_time = time.time()
    session = requests.Session()  # Ø­ÙØ¸ Ø§ØªØµØ§Ù„
    headers = {"User-Agent": ua.random}

    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ú†Ø±Ø®Ø´ÛŒ
    for attempt in range(len(WORKING_PROXIES)):
        proxy = get_next_proxy()
        try:
            r = session.get(profile_url, headers=headers, proxies={"http": proxy, "https": proxy}, timeout=10)
            r.raise_for_status()
            break
        except Exception as e:
            logger.warning(f"Profile proxy failed (attempt {attempt + 1}): {proxy} - {e}")
            continue
    else:
        raise Exception("All proxies failed")

    soup = BeautifulSoup(r.text, "lxml")

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ URL ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø§Ø³Øª
    if "/pin/" in profile_url.lower():
        raise ValueError("This link appears to be a pin, not a profile. Please send a profile link.")

    username = profile_url.strip("/").split("/")[-1]
    profile_image = None
    pins_count = "Ù†Ø§Ù…Ø´Ø®Øµ"
    description = "Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­"

    img_tag = soup.select_one('meta[property="og:image"]')
    if img_tag:
        profile_image = img_tag.get("content")

    desc_tag = soup.select_one('meta[name="description"]')
    if desc_tag:
        description = desc_tag.get("content")

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒÙ†â€ŒÙ‡Ø§ Ø§Ø² Ù…ØªÙ† ØµÙØ­Ù‡ (Ø¨Ù‡ÛŒÙ†Ù‡: ÙÙ‚Ø· Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…ØªÙ†)
    pins_text = soup.body.get_text() if soup.body else ""  # Ù…Ø­Ø¯ÙˆØ¯ Ø¨Ù‡ body Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª
    if "pins" in pins_text.lower():
        try:
            pins_count = [int(s) for s in re.findall(r'\d+', pins_text) if s.isdigit()][0]  # Ø¨Ø§ regex Ø³Ø±ÛŒØ¹â€ŒØªØ±
        except Exception:
            pass

    profile_info = {
        "username": username,
        "profile_image": profile_image,
        "pins_count": pins_count,
        "description": description,
        "profile_url": profile_url
    }
    logger.info(f"Profile fetch time: {time.time() - start_time:.2f} seconds")
    return profile_info
# ØªØ§Ø¨Ø¹ Ù‡Ù†Ø¯Ù„ Ú©Ø±Ø¯Ù† 5 Ù„ÛŒÙ†Ú© Ù¾ÛŒÙ†ØªØ±Ø³Øª Ø¨Ù‡ ØµÙˆØ±Øª Ú¯Ø±ÙˆÙ‡ÛŒ
async def handle_multiple_pinterest_links(message: types.Message, urls: list[str]):
    loading_message = await message.answer(f"We are processing your {len(urls)} Pinterest links...")

    try:
        loop = asyncio.get_running_loop()

        # Cancel check before starting heavy work
        user_id = message.from_user.id
        if getattr(task_manager, "cancel_flags", {}).get(user_id):
            await message.bot.edit_message_text(
                chat_id=message.chat.id,
                message_id=loading_message.message_id,
                text="ğŸš« Operation canceled by user."
            )
            return

        # Fetch all contents concurrently
        tasks = [loop.run_in_executor(executor, fetch_pinterest_content, url) for url in urls]
        results = await asyncio.gather(*tasks)

        # Cancel check after heavy work
        if getattr(task_manager, "cancel_flags", {}).get(user_id):
            await message.bot.edit_message_text(
                chat_id=message.chat.id,
                message_id=loading_message.message_id,
                text="ğŸš« Operation canceled by user."
            )
            return

        # Build media group
        media_group = []
        descriptions = []
        links_line = " ".join([f"<a href='{url}'>pin {i+1}</a>" for i, url in enumerate(urls)])

        for i, (content_type, file_url, single_caption) in enumerate(results):
            # Extract description from single_caption
            desc_match = re.search(r'Description: (.+?)\nSource:', single_caption)
            desc = desc_match.group(1) if desc_match else 'No description'
            descriptions.append(desc)

            if content_type == "image":
                local_file = await pinterest_download(file_url, ".jpg")
                media = types.InputMediaPhoto(media=types.FSInputFile(local_file))
            elif content_type == "video":
                local_file = await pinterest_download(file_url, ".mp4")
                media = types.InputMediaVideo(media=types.FSInputFile(local_file))
            else:
                continue  # Skip if unknown

            media_group.append(media)

        # Set caption on the first media after collecting all descriptions
        if media_group:
            descriptions_text = "\n".join([f"<blockquote>{desc}</blockquote>" for desc in descriptions])
            media_group[0].caption = f"{links_line}\n\nDescriptions:\n{descriptions_text}\n\nDownload by <a href='https://t.me/Faryseneaidownloderbot'>Faryseneaidownloderbot</a>"
            media_group[0].parse_mode = "HTML"

        # Send media group
        await message.bot.send_media_group(chat_id=message.chat.id, media=media_group)
        await message.bot.delete_message(chat_id=message.chat.id, message_id=loading_message.message_id)
        await message.delete()

    except asyncio.CancelledError:
        try:
            await message.bot.edit_message_text(
                chat_id=message.chat.id,
                message_id=loading_message.message_id,
                text="ğŸš« Operation canceled by user."
            )
        except Exception:
            pass
        raise
    except Exception as e:
        logger.error(f"Multiple Pinterest Error: {e}")
        await message.bot.edit_message_text(
            chat_id=message.chat.id,
            message_id=loading_message.message_id,
            text="Sorry, an error occurred while processing your 5 links. Please try again later."
        )
